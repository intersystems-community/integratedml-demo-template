{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train an IntegratedML model to Predict Hospital Readmission\n",
    "## Using UCI Diabetes 130-US Hospitals Dataset\n",
    "\n",
    "This Notebook demonstrates:\n",
    "- Using the `intersystems-irispython` DB-API driver to connect to InterSystems IRIS\n",
    "- Creating views to segment data into training and test sets with balanced sampling\n",
    "- Defining and training an IntegratedML model to predict 30-day hospital readmissions\n",
    "- Comparing the resulting model's predictions to data in the test set\n",
    "- Using the IntegratedML \"VALIDATE MODEL\" command to calculate accuracy metrics\n",
    "\n",
    "**Dataset:** UCI Machine Learning Repository - Diabetes 130-US Hospitals for Years 1999-2008\n",
    "\n",
    "This dataset contains ~100,000 hospital admission records for diabetic patients, with a `readmitted` column indicating:\n",
    "- `NO` - No readmission\n",
    "- `>30` - Readmitted after 30 days\n",
    "- `<30` - Readmitted within 30 days (our target for prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Connect to InterSystems IRIS using DB-API Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InterSystems IRIS DB-API Driver connection\n",
    "# Using the official intersystems-irispython package from PyPI\n",
    "import iris\n",
    "import pandas as pd\n",
    "\n",
    "# Connection configuration\n",
    "connection_string = \"irisimlsvr:1972/USER\"\n",
    "username = \"SUPERUSER\"\n",
    "password = \"SYS\"\n",
    "\n",
    "# Establish connection\n",
    "conn = iris.connect(connection_string, username, password)\n",
    "curs = conn.cursor()\n",
    "print(\"Connected to InterSystems IRIS successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define table names for our workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source data table (loaded from UCI Diabetes dataset)\n",
    "dataTable = 'Diabetes.Readmission'\n",
    "\n",
    "# Views we'll create for training and testing\n",
    "TargetTable = 'Diabetes.ReadmissionTarget'\n",
    "TrainTable = 'Diabetes.ReadmissionTraining'\n",
    "TestTable = 'Diabetes.ReadmissionTesting'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Explore the source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the data\n",
    "df = pd.read_sql(\"SELECT TOP 10 * FROM %s\" % dataTable, conn)\n",
    "display(df)\n",
    "print(f\"\\nColumns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show total record count\n",
    "df_count = pd.read_sql(\"SELECT COUNT(*) as TotalRecords FROM %s\" % dataTable, conn)\n",
    "display(df_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show distribution of readmission values\n",
    "# Note: 'Count' is a reserved word in IRIS SQL, so we use 'RecCount' instead\n",
    "df_dist = pd.read_sql(\"\"\"\n",
    "    SELECT readmitted, COUNT(*) as RecCount \n",
    "    FROM %s \n",
    "    GROUP BY readmitted\n",
    "\"\"\" % dataTable, conn)\n",
    "display(df_dist)\n",
    "print(\"\\nNote: '<30' means readmitted within 30 days (our positive class)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Clean up any previous runs (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these lines to clean up before re-running\n",
    "# curs.execute(\"DROP VIEW %s\" % TrainTable)\n",
    "# curs.execute(\"DROP VIEW %s\" % TestTable)\n",
    "# curs.execute(\"DROP VIEW %s\" % TargetTable)\n",
    "# curs.execute(\"DROP MODEL ReadmitModel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create Target View with Binary Classification\n",
    "\n",
    "We'll create a binary target variable:\n",
    "- `1` = Readmitted within 30 days (`<30`)\n",
    "- `0` = Not readmitted within 30 days (`NO` or `>30`)\n",
    "\n",
    "We'll also select the most relevant features for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the target view with binary classification and selected features\n",
    "# Note: Column names have underscores (e.g., time_in_hospital, not timeinhospital)\n",
    "curs.execute(\"\"\"\n",
    "    CREATE VIEW %s AS \n",
    "    SELECT \n",
    "        ID,\n",
    "        CASE WHEN LEFT(readmitted,1) = '<' THEN 1 ELSE 0 END AS ReadmitWithin30,\n",
    "        age,\n",
    "        gender,\n",
    "        race,\n",
    "        time_in_hospital,\n",
    "        num_medications,\n",
    "        number_emergency,\n",
    "        number_inpatient,\n",
    "        number_outpatient,\n",
    "        number_diagnoses,\n",
    "        num_lab_procedures,\n",
    "        num_procedures,\n",
    "        diabetesMed,\n",
    "        insulin,\n",
    "        metformin\n",
    "    FROM %s\n",
    "\"\"\" % (TargetTable, dataTable))\n",
    "\n",
    "# Verify the view\n",
    "df_target = pd.read_sql(\"SELECT TOP 5 * FROM %s\" % TargetTable, conn)\n",
    "display(df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check target variable distribution in our view\n",
    "df_dist2 = pd.read_sql(\"\"\"\n",
    "    SELECT ReadmitWithin30, COUNT(*) as RecCount \n",
    "    FROM %s \n",
    "    GROUP BY ReadmitWithin30\n",
    "\"\"\" % TargetTable, conn)\n",
    "display(df_dist2)\n",
    "\n",
    "total = df_dist2['RecCount'].sum()\n",
    "positive = df_dist2[df_dist2['ReadmitWithin30'] == 1]['RecCount'].values[0]\n",
    "print(f\"\\nPositive class rate: {positive/total*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create Training and Testing Views\n",
    "\n",
    "Split the data into 80% training and 20% testing using ID-based partitioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the max ID to determine split point\n",
    "max_id_df = pd.read_sql(\"SELECT MAX(ID) as MaxID FROM %s\" % TargetTable, conn)\n",
    "max_id = max_id_df['MaxID'].iloc[0]\n",
    "split_point = int(max_id * 0.8)\n",
    "\n",
    "print(f\"Max ID: {max_id}\")\n",
    "print(f\"Split point (80% training): {split_point}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Training view (80% of data)\n",
    "curs.execute(\"\"\"\n",
    "    CREATE VIEW %s AS \n",
    "    SELECT * FROM %s \n",
    "    WHERE ID <= %d\n",
    "\"\"\" % (TrainTable, TargetTable, split_point))\n",
    "\n",
    "# Create Testing view (20% of data)\n",
    "curs.execute(\"\"\"\n",
    "    CREATE VIEW %s AS \n",
    "    SELECT * FROM %s \n",
    "    WHERE ID > %d\n",
    "\"\"\" % (TestTable, TargetTable, split_point))\n",
    "\n",
    "# Verify splits\n",
    "train_count = pd.read_sql(\"SELECT COUNT(*) as RecCount FROM %s\" % TrainTable, conn)\n",
    "test_count = pd.read_sql(\"SELECT COUNT(*) as RecCount FROM %s\" % TestTable, conn)\n",
    "\n",
    "print(f\"Training records: {train_count['RecCount'].iloc[0]}\")\n",
    "print(f\"Testing records: {test_count['RecCount'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Create and Train the IntegratedML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ML configuration to use AutoML\n",
    "curs.execute(\"SET ML CONFIGURATION %AutoML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model - predicting ReadmitWithin30 (binary: 0 or 1)\n",
    "curs.execute(\"\"\"\n",
    "    CREATE MODEL ReadmitModel \n",
    "    PREDICTING (ReadmitWithin30) \n",
    "    FROM %s\n",
    "\"\"\" % TrainTable)\n",
    "\n",
    "print(\"Model created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using AutoML\n",
    "# This will take a few minutes as AutoML tries different algorithms\n",
    "print(\"Training model... this may take a few minutes...\")\n",
    "curs.execute(\"TRAIN MODEL ReadmitModel\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View information about the trained model\n",
    "df_models = pd.read_sql(\"\"\"\n",
    "    SELECT MODEL_NAME, TRAINED_MODEL_NAME, PROVIDER, MODEL_TYPE, MODEL_INFO \n",
    "    FROM INFORMATION_SCHEMA.ML_TRAINED_MODELS\n",
    "    WHERE MODEL_NAME = 'ReadmitModel'\n",
    "\"\"\", conn)\n",
    "display(df_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Compare Model Predictions to Actual Data\n",
    "\n",
    "Now we test the model on data it has never seen (the test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions vs actual values on test set\n",
    "df_predictions = pd.read_sql(\"\"\"\n",
    "    SELECT \n",
    "        PREDICT(ReadmitModel) AS PredictedReadmit,\n",
    "        ReadmitWithin30 AS ActualReadmit\n",
    "    FROM %s\n",
    "\"\"\" % TestTable, conn)\n",
    "\n",
    "display(df_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix\n",
    "confusion = pd.crosstab(\n",
    "    df_predictions['ActualReadmit'], \n",
    "    df_predictions['PredictedReadmit'],\n",
    "    rownames=['Actual'],\n",
    "    colnames=['Predicted']\n",
    ")\n",
    "print(\"Confusion Matrix:\")\n",
    "display(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy metrics manually\n",
    "correct = (df_predictions['PredictedReadmit'] == df_predictions['ActualReadmit']).sum()\n",
    "total = len(df_predictions)\n",
    "accuracy = correct / total * 100\n",
    "\n",
    "print(f\"\\nManual Accuracy Calculation:\")\n",
    "print(f\"Correct predictions: {correct}\")\n",
    "print(f\"Total predictions: {total}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. VALIDATE MODEL - IntegratedML's Built-in Metrics\n",
    "\n",
    "IntegratedML provides comprehensive validation metrics automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run VALIDATE MODEL to generate accuracy metrics\n",
    "curs.execute(\"VALIDATE MODEL ReadmitModel FROM %s\" % TestTable)\n",
    "\n",
    "# Get the most recent validation run for this model\n",
    "df_metrics = pd.read_sql(\"\"\"\n",
    "    SELECT * FROM INFORMATION_SCHEMA.ML_VALIDATION_METRICS \n",
    "    WHERE MODEL_NAME = 'ReadmitModel'\n",
    "    ORDER BY VALIDATION_RUN_NAME DESC\n",
    "\"\"\", conn)\n",
    "\n",
    "# Get only the latest validation run and remove any duplicate metrics\n",
    "latest_run = df_metrics['VALIDATION_RUN_NAME'].iloc[0]\n",
    "df_latest = df_metrics[df_metrics['VALIDATION_RUN_NAME'] == latest_run].drop_duplicates(\n",
    "    subset=['VALIDATION_RUN_NAME', 'METRIC_NAME'], keep='first'\n",
    ")\n",
    "\n",
    "# Pivot to display metrics in a readable format\n",
    "df_pivot = df_latest.pivot(index='VALIDATION_RUN_NAME', columns='METRIC_NAME', values='METRIC_VALUE')\n",
    "display(df_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Query High-Risk Patients Using PROBABILITY()\n",
    "\n",
    "Find patients with high probability of 30-day readmission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get patients with high readmission probability\n",
    "df_highrisk = pd.read_sql(\"\"\"\n",
    "    SELECT \n",
    "        ID,\n",
    "        PROBABILITY(ReadmitModel FOR '1') AS ReadmitProbability,\n",
    "        PREDICT(ReadmitModel) AS PredictedReadmit,\n",
    "        ReadmitWithin30 AS ActualReadmit,\n",
    "        age,\n",
    "        time_in_hospital,\n",
    "        num_medications,\n",
    "        number_emergency,\n",
    "        number_inpatient\n",
    "    FROM %s\n",
    "    WHERE PROBABILITY(ReadmitModel FOR '1') >= 0.3\n",
    "    ORDER BY PROBABILITY(ReadmitModel FOR '1') DESC\n",
    "\"\"\" % TestTable, conn)\n",
    "\n",
    "print(f\"Found {len(df_highrisk)} high-risk patients (probability >= 30%)\")\n",
    "display(df_highrisk.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Analyze Misclassified Cases\n",
    "\n",
    "Look at cases where the model was wrong - this helps understand model limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find false negatives - patients who were readmitted but model predicted they wouldn't be\n",
    "df_false_neg = pd.read_sql(\"\"\"\n",
    "    SELECT \n",
    "        PROBABILITY(ReadmitModel FOR '1') AS ReadmitProbability,\n",
    "        PREDICT(ReadmitModel) AS PredictedReadmit,\n",
    "        ReadmitWithin30 AS ActualReadmit,\n",
    "        age,\n",
    "        gender,\n",
    "        time_in_hospital,\n",
    "        num_medications,\n",
    "        number_emergency,\n",
    "        number_inpatient\n",
    "    FROM %s\n",
    "    WHERE ReadmitWithin30 = 1 \n",
    "      AND PREDICT(ReadmitModel) = 0\n",
    "\"\"\" % TestTable, conn)\n",
    "\n",
    "print(f\"False Negatives (missed readmissions): {len(df_false_neg)}\")\n",
    "display(df_false_neg.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find false positives - patients predicted to readmit but didn't\n",
    "df_false_pos = pd.read_sql(\"\"\"\n",
    "    SELECT \n",
    "        PROBABILITY(ReadmitModel FOR '1') AS ReadmitProbability,\n",
    "        PREDICT(ReadmitModel) AS PredictedReadmit,\n",
    "        ReadmitWithin30 AS ActualReadmit,\n",
    "        age,\n",
    "        gender,\n",
    "        time_in_hospital,\n",
    "        num_medications,\n",
    "        number_emergency,\n",
    "        number_inpatient\n",
    "    FROM %s\n",
    "    WHERE ReadmitWithin30 = 0 \n",
    "      AND PREDICT(ReadmitModel) = 1\n",
    "\"\"\" % TestTable, conn)\n",
    "\n",
    "print(f\"False Positives (predicted readmit but didn't): {len(df_false_pos)}\")\n",
    "display(df_false_pos.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Data Preparation**: Converting the UCI Diabetes dataset's readmission categories into a binary classification problem\n",
    "2. **Train/Test Split**: Using SQL views to partition data for training and validation\n",
    "3. **Model Training**: Using IntegratedML's AutoML to automatically select and train the best model\n",
    "4. **Prediction**: Using `PREDICT()` to get model predictions on new data\n",
    "5. **Validation**: Using `VALIDATE MODEL` to get comprehensive accuracy metrics\n",
    "6. **Risk Scoring**: Using `PROBABILITY()` to identify high-risk patients for intervention\n",
    "\n",
    "**Clinical Application**: In a real healthcare setting, this model could be used to:\n",
    "- Identify patients at risk of early readmission before discharge\n",
    "- Prioritize follow-up care and resources\n",
    "- Trigger care coordination interventions for high-risk patients"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
