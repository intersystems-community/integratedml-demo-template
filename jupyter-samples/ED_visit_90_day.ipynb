{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Train an IntegratedML model on ED Readmit likelihood Dataset\n\n**NOTE: This Notebook will not run as-is!**\n\nThis notebook requires:\n- External data (Data.PatientCostData table)\n- Custom connection script (Initializations/Conns.py)\n\nTo adapt for the DB-API driver, replace the connection setup with:\n```python\nimport iris\nconn = iris.connect(\"irisimlsvr:1972/USER\", \"SUPERUSER\", \"SYS\")\ncurs = conn.cursor()\n```\n\nThis Notebook demonstrates:\n- Creating views to segment data into training and test sets\n- Defining and training an IntegratedML model to predict ED Readmits in the next 90 days\n- Comparing the resulting model's predictions to data in the test set\n- Using the IntegratedML \"VALIDATE MODEL\" command to calculate accuracy metrics"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 1. Get connection and cursor"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i '../Initializations/Conns.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create and specify the source data table(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this block to create a starting data set that you can/will build upon.\n",
    "#NOTE: It is always useful to have a unique identifier in the data\n",
    "TargetTable = 'Data.EDEncsPredB90View'\n",
    "TrainTable = 'Data.EDEncsTraining'\n",
    "TestTable = 'Data.EDEncsTesting'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Review the data to ensure the Target variable and Independent variables are in good standing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tKeep()\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "df = pd.read_sql(\"select top 3 * from Data.PatientCostData\", iconn)\n",
    "print(df)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop and unwanted fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['T30', 'T60', 'T90'], axis = 1)\n",
    "Usable = str(list(df.columns)).replace(\"', '\", \",\")[2:-2]\n",
    "Usable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icurs.execute(' \\\n",
    "    create or replace view %s as \\\n",
    "        select case when t90 > 0 then 1 else 0 end as B90, %s \\\n",
    "        from Data.PatientCostData' % (TargetTable, Usable))\n",
    "df1 = pd.read_sql('SELECT COUNT(*) as Recs FROM %s' % TargetTable, iconn)\n",
    "TargetVar = 'B90'\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Distro = pd.read_sql('select %s, count(*) as Recs from %s group by %s' % (TargetVar, TargetTable, TargetVar), iconn)\n",
    "Distro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Assess the probability of your target and sample accordingly into split training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want to split the data into Training (80%) and Test (20%), ...\n",
    "# but also reduce the ratio of Negative (ED Enc = 0) to Positive\n",
    "Train = 0.8\n",
    "TVRatio = 2\n",
    "PT_List = pd.read_sql('select DRID, %s from %s order by %s, DRID' % (TargetVar, TargetTable, TargetVar), iconn)\n",
    "PT_List.index = PT_List['DRID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create the lists, check the ratios, and create the \"In lists\":\n",
    "TrainList = PT_List[PT_List[TargetVar] == 0].sample(int(Distro['Recs'].loc[1]*TVRatio*Train)) \\\n",
    "    .append(PT_List[PT_List[TargetVar] == 1].sample(int(Distro['Recs'].loc[1]*Train)))\n",
    "TrainList['Flag'] = 1\n",
    "TrainList.index = TrainList['DRID']\n",
    "print(TrainList.pivot_table(index = TargetVar, values = 'DRID', aggfunc = 'count'))\n",
    "#NOTE: It is IMPERATIVE that Test does NOT contain any Train data\n",
    "TestList = PT_List.join(TrainList['Flag'], how = 'left')\n",
    "TestList = TestList[(TestList['Flag'] != 1)]\n",
    "TestList = TestList[(TestList[TargetVar] == 1)].append(TestList[TestList[TargetVar] == 0].sample(int(len(TestList)*0.25)))\n",
    "print(TestList.pivot_table(index = TargetVar, values = 'DRID', aggfunc = 'count'))\n",
    "TrainIns = str(list(TrainList['DRID']))[1:-1]\n",
    "TestIns = str(list(TestList['DRID']))[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set view\n",
    "icurs.execute(''' \\\n",
    "    CREATE or replace VIEW %s AS \\\n",
    "        SELECT * FROM %s \n",
    "        WHERE DRID in (%s)''' \\\n",
    "    % (TrainTable, TargetTable, TrainIns))\n",
    "# Prediction set\n",
    "icurs.execute(''' \\\n",
    "    CREATE or replace VIEW %s AS \\\n",
    "        SELECT * FROM %s \n",
    "        WHERE DRID in (%s)''' \\\n",
    "    % (TestTable, TargetTable, TestIns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create and Train an IntegratedML Model using default settings\n",
    "IntegratedML only needs a model name, the name of the column that is the target column to predict, and a table (or SELECT query to specify input columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    icurs.execute(\"CREATE MODEL NewEncModel PREDICTING (%s) FROM %s\" % (TargetVar, TrainTable))\n",
    "except:\n",
    "    icurs.execute(\"DROP MODEL NewEncModel\")\n",
    "    icurs.execute(\"CREATE MODEL NewEncModel PREDICTING (%s) FROM %s\" % (TargetVar, TrainTable))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is defined, you can TRAIN it, which invokes the AutoML machine learning procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icurs.execute(\"set ml configuration %AutoML\")\n",
    "icurs.execute(\"TRAIN MODEL NewEncModel as NewEncModel_Auto\")\n",
    "icurs.execute(\"set ml configuration DRCfg\")\n",
    "icurs.execute(\"TRAIN MODEL NewEncModel as NewEncModel_DR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once that finishes, you can see some information about the model in the \"ML_TRAINED_MODELS\" table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\"SELECT * FROM INFORMATION_SCHEMA.ML_TRAINED_MODELS\", iconn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Compare model output to data it has not seen yet\n",
    "Now you can use SQL to SELECT data from another table, run the IntegratedML model on this new data, and see how well the predictions match the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestSet = pd.read_sql('''\n",
    "    SELECT PREDICT(NewEncModel use NewEncModel_Auto) AS PredictedEncs,\n",
    "        case when B90 = 1 then 1 end AS ActualPos,\n",
    "        case when B90 != 1 then 0 end AS ActualNeg\n",
    "    FROM %s''' % (TestTable), iconn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.pivot_table(TestSet, index = 'PredictedEncs', values = ['ActualPos', 'ActualNeg'], aggfunc = 'count'))\n",
    "print('Accuracy: '+str(round((len(TestSet[(TestSet['PredictedEncs'] == TestSet['ActualPos']) \\\n",
    "            | (TestSet['PredictedEncs'] == TestSet['ActualNeg'])])/len(TestSet))*100))+'%')\n",
    "print('Misclassification Rate: '+str(round((len(TestSet[(TestSet['PredictedEncs'] != TestSet['ActualPos']) \\\n",
    "            & (TestSet['PredictedEncs'] != TestSet['ActualNeg'])])/len(TestSet))*100))+'%')\n",
    "print('%FP: '+str(round((len(TestSet[(TestSet['PredictedEncs'] == 1) & (TestSet['ActualNeg'] == 0)])/ \\\n",
    "            len(TestSet[TestSet['ActualNeg'] == 0]))*100))+'%')\n",
    "print('%FN: '+str(round((len(TestSet[(TestSet['PredictedEncs'] == 0) & (TestSet['ActualPos'] == 1)])/ \\\n",
    "            len(TestSet[TestSet['ActualPos'] == 1]))*100))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. VALIDATE MODEL command calculates accuracy metrics\n",
    "You can certainly take that output above and calculate the accuracy using a standard formula, but IntegratedML has a built-in function to do that!\n",
    "\n",
    "Each time you run the command \"VALIDATE MODEL...\" it generates a set of metrics calculated on the data passed into the query. Since this table can be a bit difficult to read in its raw form we use a simple \"pivot\" call to arrange the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icurs.execute(\"VALIDATE model NewEncModel use NewEncModel_Auto FROM Data.EDEncsTesting\")\n",
    "#df5 = pd.read_sql(\"SELECT * FROM INFORMATION_SCHEMA.ML_VALIDATION_METRICS\", iconn)\n",
    "#df5\n",
    "#df6 = df5.pivot(index='VALIDATION_RUN_NAME', columns='METRIC_NAME', values='METRIC_VALUE')\n",
    "#display(df6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}